{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holistic Results\n",
    "\n",
    "**TODO**: Fill in the `MRMC_DIR`. This should be a path (absolute or relative) to the repo's top-level directory. It is probably `../../../..`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "MRMC_DIR = None\n",
    "\n",
    "if MRMC_DIR is None:\n",
    "    raise RuntimeError(\"MRMC_DIR should have the path to the top-level directory of the MRMC repo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(MRMC_DIR)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scripts import fit_kde\n",
    "from models import model_loader, model_constants\n",
    "from data import data_loader\n",
    "from data.adapters import continuous_adapter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries -- load everything\n",
    "\n",
    "**TODO**: fill in values for `RECOURSE_METHOD`, `DATASET`, `MODEL`, and `EXPERIMENT_NAME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOURSE_METHOD = None  # mrmc, dice, or face\n",
    "DATASET_NAME = None  # credit_card_default or give_me_credit\n",
    "MODEL_TYPE = None  # logistic_regression or random_forest\n",
    "EXPERIMENT_NAME = None  # typically something like mrmc_holistic or dice_hyperparam\n",
    "RESULTS_DIR = os.path.join(MRMC_DIR, 'experiment_results', RECOURSE_METHOD, MODEL_TYPE, DATASET_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "if None in [RECOURSE_METHOD, DATASET_NAME, MODEL_TYPE]:\n",
    "    raise RuntimeError(\"Values for RECOURSE_METHOD, DATASET, and MODEL must be provided.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET, DATASET_INFO = data_loader.load_data(data_loader.DatasetName(DATASET_NAME), split=\"train\")\n",
    "MODEL = model_loader.load_model(model_constants.ModelType(MODEL_TYPE), data_loader.DatasetName(DATASET_NAME))\n",
    "ADAPTER = continuous_adapter.StandardizingAdapter(\n",
    "    label_column = DATASET_INFO.label_column, positive_label=DATASET_INFO.positive_label\n",
    ").fit(DATASET)\n",
    "\n",
    "DROP_COLUMNS = ['step_id', 'path_id', 'run_id', 'batch_id']  # columns which are convenient to drop from the path_df\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, 'config.json')) as f:\n",
    "    config_json = json.load(f)\n",
    "\n",
    "EVAL_SPLIT = config_json['split']\n",
    "EVAL_DATASET, _ = data_loader.load_data(data_loader.DatasetName(DATASET_NAME), split=EVAL_SPLIT)\n",
    "\n",
    "\n",
    "#  If using MRMC, load the cluster DF\n",
    "if RECOURSE_METHOD == 'mrmc':\n",
    "    cluster_df = pd.read_csv(os.path.join(RESULTS_DIR, 'cluster_df.csv'))\n",
    "config_df = pd.read_csv(os.path.join(RESULTS_DIR, 'experiment_config_df.csv'))\n",
    "#  If using FACE, retrieve the distance_threshold and weight_bias from the graph config\n",
    "if RECOURSE_METHOD == 'face':\n",
    "    graph_filepaths = config_df.graph_filepath.unique()\n",
    "    distance_thresholds = []\n",
    "    weight_biases = []\n",
    "    for graph_filepath in graph_filepaths:\n",
    "        graph_config_filepath = os.path.join(MRMC_DIR, graph_filepath[:-4] + '_config.json')\n",
    "        with open(graph_config_filepath) as f:\n",
    "            graph_config = json.load(f)\n",
    "            distance_thresholds.append(graph_config['distance_threshold'])\n",
    "            weight_biases.append(graph_config['weight_bias'])\n",
    "    graph_config_df = pd.DataFrame({\n",
    "        'graph_filepath': graph_filepaths,\n",
    "        'distance_threshold': distance_thresholds,\n",
    "        'weight_bias': weight_biases\n",
    "    })\n",
    "    config_df = config_df.merge(graph_config_df, how='left', on='graph_filepath')\n",
    "path_df = pd.read_csv(os.path.join(RESULTS_DIR, f'{RECOURSE_METHOD}_paths_df.csv'))\n",
    "config_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Fit a KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_DIRECTORY = os.path.join(MRMC_DIR, f'saved_models/kde/{DATASET_NAME}_kde.joblib')\n",
    "\n",
    "if os.path.exists(KDE_DIRECTORY):\n",
    "    KDE = joblib.load(KDE_DIRECTORY)\n",
    "else:\n",
    "    KDE = fit_kde.fit_kde(DATASET_NAME, KDE_DIRECTORY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARSITY_EPSILON = 1e-5\n",
    "\n",
    "def get_poi_cfes(path_df: pd.DataFrame):\n",
    "    \"\"\"Isolate the POIs (Points of Interest) and CFEs (Counterfactual Examples) from the full path results.\n",
    "    \n",
    "    POIs and CFEs are listed in the order they originally appear in. There is one POI and one CFE\n",
    "    for every path that appears in the DataFrame.\"\"\"\n",
    "    pathscopy = path_df.copy()\n",
    "    pathscopy['next_step_id'] = 0\n",
    "    pathscopy.loc[:,'next_step_id'].iloc[0:-1] = pathscopy.loc[:,'step_id'].iloc[1:]\n",
    "    cfes = pathscopy[pathscopy.step_id >= pathscopy.next_step_id].drop(columns='next_step_id')\n",
    "    return pathscopy[pathscopy.step_id == 0].drop(columns='next_step_id'), cfes\n",
    "\n",
    "def get_sparsity(path: pd.DataFrame):\n",
    "    \"\"\"Returns the maximum number of features changed in any single iteration\n",
    "    along the path.\"\"\"\n",
    "    if path.shape[0] == 1:\n",
    "        return np.nan\n",
    "    path_sparsity = np.zeros(path.shape[0])\n",
    "    for i in range(1, path.shape[0]):\n",
    "        path_sparsity[i] = (np.abs(path.iloc[i] - path.iloc[i - 1]) > SPARSITY_EPSILON).sum()\n",
    "    return np.max(path_sparsity)\n",
    "\n",
    "def get_path_length(path: pd.DataFrame):\n",
    "    \"\"\"Returns the sum of euclidean distances along the path.\"\"\"\n",
    "    total = 0\n",
    "    for i in range(1, path.shape[0]):\n",
    "        total += np.linalg.norm(path.iloc[i] - path.iloc[i - 1])\n",
    "    if total == 0:\n",
    "        return np.nan\n",
    "    return total\n",
    "\n",
    "def get_cfe_distance(path: pd.DataFrame):\n",
    "    \"\"\"Returns the euclidean distance between the first and last points in the path.\"\"\"\n",
    "    if len(path) == 1:\n",
    "        return np.nan\n",
    "    return np.linalg.norm(path.iloc[-1] - path.iloc[0])\n",
    "\n",
    "\n",
    "def analyze_paths(paths: pd.DataFrame, poi_kdes, cfe_kdes, cfe_probs, config_df):\n",
    "    \"\"\"Returns a DataFrame containing per-path results.\n",
    "    \n",
    "    Each row corresponds to a specific path. Each column is a result metric.\n",
    "    \n",
    "    Args:\n",
    "        paths: The path_df DataFrame to analyze.\n",
    "        poi_kdes: The KDE scores for the POIs.\n",
    "        cfe_kdes: The KDE scores for the CFEs.\n",
    "        config_df: The experiment_config_df for the experiment.\"\"\"\n",
    "    columns = ['run_id', 'path_id', 'success', 'proximity', 'path_length',\n",
    "               'iteration_count', 'poi_density', 'cfe_density', \n",
    "               'actual_sparsity']\n",
    "    col_idx = {}\n",
    "    for i, col in enumerate(columns):\n",
    "        col_idx[col] = i\n",
    "\n",
    "    results = np.zeros((len(poi_kdes), len(columns)))\n",
    "\n",
    "    i = 0\n",
    "    for run_id in paths.run_id.unique():\n",
    "        run_paths = paths[paths.run_id == run_id]\n",
    "        for path_id in run_paths.path_id.unique():\n",
    "            path = ADAPTER.transform(run_paths[run_paths.path_id == path_id].drop(columns=DROP_COLUMNS))\n",
    "            results[i,col_idx['run_id']] = run_id\n",
    "            results[i,col_idx['path_id']] = path_id\n",
    "\n",
    "            desired_proba = config_df[config_df.run_id == run_id].confidence_cutoff.iloc[0]\n",
    "            actual_proba = cfe_probs[i]\n",
    "\n",
    "            results[i,col_idx['success']] = 1 if actual_proba >= desired_proba else 0\n",
    "            results[i,col_idx['path_length']] = get_path_length(path)\n",
    "            results[i,col_idx['iteration_count']] = len(path)\n",
    "            results[i,col_idx['proximity']] = get_cfe_distance(path)\n",
    "            results[i,col_idx['poi_density']] = poi_kdes[i]\n",
    "            results[i,col_idx['cfe_density']] = cfe_kdes[i]\n",
    "            results[i,col_idx['actual_sparsity']] = get_sparsity(path)\n",
    "            i += 1\n",
    "\n",
    "    return pd.DataFrame(data=results, columns=columns)\n",
    "\n",
    "pois, cfes = get_poi_cfes(path_df)\n",
    "poi_kdes = KDE.score_samples(ADAPTER.transform(pois.drop(columns=DROP_COLUMNS)))\n",
    "cfe_kdes = KDE.score_samples(ADAPTER.transform(cfes.drop(columns=DROP_COLUMNS)))\n",
    "cfe_probs = MODEL.predict_pos_proba(cfes.drop(columns=DROP_COLUMNS)).to_numpy()\n",
    "\n",
    "results = analyze_paths(path_df, poi_kdes, cfe_kdes, cfe_probs, config_df)\n",
    "results = results.merge(config_df, how='left', on='run_id').drop(\n",
    "    columns=['max_iterations', 'noise_ratio',\n",
    "             'rescale_ratio', 'cluster_seed', 'run_seed',\n",
    "             'volcano_degree', 'volcano_cutoff'])  # uninteresting columns\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "544bbcec4a3402c4ea95887680bbb478b7040f8d29544f0f161653d15df00b63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
