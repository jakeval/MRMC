{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../..'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from models import model_interface, model_loader, model_constants\n",
    "from data import data_loader\n",
    "from data.adapters import continuous_adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries -- load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakeval/umass/research/.venv/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/jakeval/umass/research/.venv/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.1.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_seed</th>\n",
       "      <th>confidence_cutoff</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>max_iterations</th>\n",
       "      <th>max_step_size</th>\n",
       "      <th>model_type</th>\n",
       "      <th>noise_ratio</th>\n",
       "      <th>num_paths</th>\n",
       "      <th>rescale_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>227</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>227</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>9251</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>4404</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>6779</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>171</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1498</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3439</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3069</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>5403</td>\n",
       "      <td>0.7</td>\n",
       "      <td>credit_card_default</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_id  run_id  run_seed  confidence_cutoff         dataset_name  \\\n",
       "0          2      89       227                0.7  credit_card_default   \n",
       "1          0      29       227                0.7  credit_card_default   \n",
       "2          2      81      9251                0.7  credit_card_default   \n",
       "3          2      64      4404                0.7  credit_card_default   \n",
       "4          0      28      6779                0.7  credit_card_default   \n",
       "..       ...     ...       ...                ...                  ...   \n",
       "85         0      22       171                0.7  credit_card_default   \n",
       "86         2      69      1498                0.7  credit_card_default   \n",
       "87         0      15      3439                0.7  credit_card_default   \n",
       "88         0      24      3069                0.7  credit_card_default   \n",
       "89         2      85      5403                0.7  credit_card_default   \n",
       "\n",
       "    max_iterations  max_step_size           model_type  noise_ratio  \\\n",
       "0               30            NaN  logistic_regression          NaN   \n",
       "1               30            1.0  logistic_regression          NaN   \n",
       "2               30            NaN  logistic_regression          NaN   \n",
       "3               30            NaN  logistic_regression          NaN   \n",
       "4               30            1.0  logistic_regression          NaN   \n",
       "..             ...            ...                  ...          ...   \n",
       "85              30            1.0  logistic_regression          NaN   \n",
       "86              30            NaN  logistic_regression          NaN   \n",
       "87              30            1.0  logistic_regression          NaN   \n",
       "88              30            1.0  logistic_regression          NaN   \n",
       "89              30            NaN  logistic_regression          NaN   \n",
       "\n",
       "    num_paths  rescale_ratio  \n",
       "0           3            NaN  \n",
       "1           3            NaN  \n",
       "2           3            NaN  \n",
       "3           3            NaN  \n",
       "4           3            NaN  \n",
       "..        ...            ...  \n",
       "85          3            NaN  \n",
       "86          3            NaN  \n",
       "87          3            NaN  \n",
       "88          3            NaN  \n",
       "89          3            NaN  \n",
       "\n",
       "[90 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET, DATASET_INFO = data_loader.load_data(data_loader.DatasetName('credit_card_default'))\n",
    "MODEL = model_loader.load_model(model_constants.ModelType('logistic_regression'), data_loader.DatasetName('credit_card_default'))\n",
    "ADAPTER = continuous_adapter.StandardizingAdapter(\n",
    "    label_column = DATASET_INFO.label_column, positive_label=DATASET_INFO.positive_label\n",
    ").fit(DATASET)\n",
    "\n",
    "results_dir = '../../../experiment_results/dice_results/dice_step_size'\n",
    "\n",
    "index_df = pd.read_csv(os.path.join(results_dir, 'experiment_config_df.csv'))\n",
    "path_df = pd.read_csv(os.path.join(results_dir, 'dice_paths_df.csv'))\n",
    "index_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate bandwidth 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m train_indices, val_indices \u001b[39min\u001b[39;00m kfold\u001b[39m.\u001b[39msplit(transformed_data):\n\u001b[1;32m     11\u001b[0m     kde \u001b[39m=\u001b[39m neighbors\u001b[39m.\u001b[39mKernelDensity(bandwidth\u001b[39m=\u001b[39mbw)\u001b[39m.\u001b[39mfit(transformed_data\u001b[39m.\u001b[39miloc[train_indices])\n\u001b[0;32m---> 12\u001b[0m     score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m kde\u001b[39m.\u001b[39;49mscore(transformed_data\u001b[39m.\u001b[39;49miloc[val_indices])\n\u001b[1;32m     13\u001b[0m scores\u001b[39m.\u001b[39mappend(score \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(bandwidths))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/umass/research/.venv/lib/python3.8/site-packages/sklearn/neighbors/_kde.py:271\u001b[0m, in \u001b[0;36mKernelDensity.score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    252\u001b[0m     \u001b[39m\"\"\"Compute the total log-likelihood under the model.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[1;32m    254\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m        data.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_samples(X))\n",
      "File \u001b[0;32m~/umass/research/.venv/lib/python3.8/site-packages/sklearn/neighbors/_kde.py:239\u001b[0m, in \u001b[0;36mKernelDensity.score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m     N \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39msum_weight\n\u001b[1;32m    238\u001b[0m atol_N \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matol \u001b[39m*\u001b[39m N\n\u001b[0;32m--> 239\u001b[0m log_density \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_\u001b[39m.\u001b[39;49mkernel_density(\n\u001b[1;32m    240\u001b[0m     X,\n\u001b[1;32m    241\u001b[0m     h\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbandwidth,\n\u001b[1;32m    242\u001b[0m     kernel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel,\n\u001b[1;32m    243\u001b[0m     atol\u001b[39m=\u001b[39;49matol_N,\n\u001b[1;32m    244\u001b[0m     rtol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrtol,\n\u001b[1;32m    245\u001b[0m     breadth_first\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbreadth_first,\n\u001b[1;32m    246\u001b[0m     return_log\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    247\u001b[0m )\n\u001b[1;32m    248\u001b[0m log_density \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(N)\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m log_density\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "transformed_data = ADAPTER.transform(DATASET.drop(columns='Y')).sample(frac=1, replace=False)\n",
    "\n",
    "bandwidths = np.logspace(-1, 0, 6)\n",
    "scores = []\n",
    "\n",
    "for bw in bandwidths:\n",
    "    print(\"Evaluate bandwidth\", bw)\n",
    "    score = 0\n",
    "    for train_indices, val_indices in kfold.split(transformed_data):\n",
    "        kde = neighbors.KernelDensity(bandwidth=bw).fit(transformed_data.iloc[train_indices])\n",
    "        score += kde.score(transformed_data.iloc[val_indices])\n",
    "    scores.append(score / len(bandwidths))\n",
    "    print(scores[-1])\n",
    "best_bandwidth = bandwidths[np.argmax(scores)]\n",
    "print(\"Finished! Selected bandwidth is \", best_bandwidth)\n",
    "KDE = neighbors.KernelDensity(bandwidth=bw).fit(transformed_data)\n",
    "print(\"Scoring full dataset...\")\n",
    "scores = KDE.score_samples(transformed_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the KDE qualitatively\n",
    "\n",
    "The scores are between -28 and -20. Unsurprisingly, most points have relatively high density.\n",
    "Overall the histogram seems reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_bandwidth = bandwidths[np.argmax(scores)]\n",
    "transformed_data = ADAPTER.transform(DATASET.drop(columns='Y')).sample(frac=1, replace=False)\n",
    "best_bandwidth = 0.251188643150958\n",
    "KDE = neighbors.KernelDensity(bandwidth=best_bandwidth).fit(transformed_data)\n",
    "#KDE_SCORES = KDE.score_samples(transformed_data)\n",
    "#sns.histplot(KDE_SCORES)\n",
    "#pd.DataFrame({'density': KDE_SCORES}).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some numpy arrays so we can pass of to numba\n",
    "# The slowest here will be KDE\n",
    "\n",
    "# order the paths dataframe\n",
    "ordered_paths = path_df.sort_values(['run_id', 'path_id', 'step_id'])\n",
    "run_ids = ordered_paths.run_id.to_numpy()\n",
    "path_ids = ordered_paths.path_id.to_numpy()\n",
    "\n",
    "# get the raw data -- we've already extracted the run_id and path_id.\n",
    "paths = ordered_paths.drop(columns=['run_id', 'batch_id', 'step_id', 'path_id'])\n",
    "\n",
    "# pos_proba and target_proba are calculated for every point in every path\n",
    "pos_proba = MODEL.predict_pos_proba(paths).to_numpy()\n",
    "target_proba = ordered_paths.merge(index_df[['run_id', 'confidence_cutoff']], how='left', on='run_id', validate='many_to_one').confidence_cutoff.to_numpy()\n",
    "\n",
    "numpy_paths = ADAPTER.transform(paths).to_numpy()\n",
    "\n",
    "# the first path begins at boundary_indices[0]. The second path begins at boundary_indices[1]. There is no path beginning at boundary_indices[-1].\n",
    "boundary_indices = np.arange(run_ids.shape[0])[(path_ids != np.hstack([[-1], path_ids[:-1]]))]\n",
    "boundary_indices = np.hstack([boundary_indices, path_ids.shape[0]])\n",
    "\n",
    "# run KDE over the POIs and CFEs\n",
    "pois = paths.iloc[boundary_indices[:-1]]\n",
    "counterfactuals = paths.iloc[boundary_indices[1:] - 1]\n",
    "poi_kde = KDE.score_samples(ADAPTER.transform(pois))\n",
    "cfe_kde = KDE.score_samples(ADAPTER.transform(counterfactuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def get_sparsity(path: np.ndarray) -> int:\n",
    "    if path.shape[0] == 1:\n",
    "        return np.nan\n",
    "    path_sparsity = np.zeros(path.shape[0])\n",
    "    for i in range(1, path.shape[0]):\n",
    "        path_sparsity[i] = ((path[i] - path[i - 1]) != 0).sum()\n",
    "    return np.max(path_sparsity)\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def get_path_length(path: np.ndarray) -> float:\n",
    "    total = 0\n",
    "    for i in range(1, path.shape[0]):\n",
    "        total += np.linalg.norm(path[i] - path[i - 1])\n",
    "    if total == 0:\n",
    "        return np.nan\n",
    "    return total\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def analyze_paths(\n",
    "    paths: np.ndarray,\n",
    "    run_ids: np.ndarray,\n",
    "    path_ids: np.ndarray,\n",
    "    pos_proba: np.ndarray,\n",
    "    target_proba: np.ndarray,\n",
    "    boundary_indices: np.ndarray,\n",
    "    poi_kde: np.ndarray,\n",
    "    cfe_kde: np.ndarray\n",
    "):\n",
    "    columns = ['run_id', 'path_id', 'success', 'path_length', 'poi_density', 'cfe_density', 'sparsity']\n",
    "    col_idx = {}\n",
    "    for i, col in enumerate(columns):\n",
    "        col_idx[col] = i\n",
    "    results = np.zeros((len(boundary_indices) - 1, len(columns)))\n",
    "    for i in range(boundary_indices.shape[0]-1):\n",
    "        start_idx, end_idx = boundary_indices[i:i+2]\n",
    "        path = paths[start_idx:end_idx]\n",
    "        results[i,col_idx['run_id']] = run_ids[start_idx]\n",
    "        results[i,col_idx['path_id']] = path_ids[start_idx]\n",
    "        results[i,col_idx['success']] = 1 if pos_proba[end_idx - 1] >= target_proba[end_idx - 1] else 0\n",
    "        results[i,col_idx['path_length']] = get_path_length(path)\n",
    "        results[i,col_idx['poi_density']] = poi_kde[i]\n",
    "        results[i,col_idx['cfe_density']] = cfe_kde[i]\n",
    "        results[i,col_idx['sparsity']] = get_sparsity(path)\n",
    "\n",
    "    return results, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>path_id</th>\n",
       "      <th>success</th>\n",
       "      <th>path_length</th>\n",
       "      <th>poi_density</th>\n",
       "      <th>cfe_density</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>confidence_cutoff</th>\n",
       "      <th>max_step_size</th>\n",
       "      <th>num_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-1.036496</td>\n",
       "      <td>-381.132768</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.036496</td>\n",
       "      <td>-373.072976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-1.036496</td>\n",
       "      <td>-32.333564</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-1.039537</td>\n",
       "      <td>-202.683678</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-1.039537</td>\n",
       "      <td>-56.756210</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.741088</td>\n",
       "      <td>3.196688</td>\n",
       "      <td>-8413.627287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.378054</td>\n",
       "      <td>3.196688</td>\n",
       "      <td>-1561.712336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.650337</td>\n",
       "      <td>-1.056702</td>\n",
       "      <td>-808.113308</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.404998</td>\n",
       "      <td>-1.056702</td>\n",
       "      <td>-12574.889835</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.222415</td>\n",
       "      <td>-1.056702</td>\n",
       "      <td>-1799.775883</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     run_id  path_id  success  path_length  poi_density   cfe_density  \\\n",
       "0       0.0      0.0      1.0    14.000000    -1.036496   -381.132768   \n",
       "1       0.0      1.0      1.0    15.000000    -1.036496   -373.072976   \n",
       "2       0.0      2.0      1.0    12.000000    -1.036496    -32.333564   \n",
       "3       1.0      0.0      1.0    17.000000    -1.039537   -202.683678   \n",
       "4       1.0      1.0      1.0    13.000000    -1.039537    -56.756210   \n",
       "..      ...      ...      ...          ...          ...           ...   \n",
       "265    88.0      1.0      1.0    44.741088     3.196688  -8413.627287   \n",
       "266    88.0      2.0      1.0    15.378054     3.196688  -1561.712336   \n",
       "267    89.0      0.0      1.0    31.650337    -1.056702   -808.113308   \n",
       "268    89.0      1.0      1.0    49.404998    -1.056702 -12574.889835   \n",
       "269    89.0      2.0      1.0    32.222415    -1.056702  -1799.775883   \n",
       "\n",
       "     sparsity  batch_id  confidence_cutoff  max_step_size  num_paths  \n",
       "0         2.0         0                0.7            1.0          3  \n",
       "1         2.0         0                0.7            1.0          3  \n",
       "2         3.0         0                0.7            1.0          3  \n",
       "3         2.0         0                0.7            1.0          3  \n",
       "4         2.0         0                0.7            1.0          3  \n",
       "..        ...       ...                ...            ...        ...  \n",
       "265       2.0         2                0.7            NaN          3  \n",
       "266       1.0         2                0.7            NaN          3  \n",
       "267       3.0         2                0.7            NaN          3  \n",
       "268       3.0         2                0.7            NaN          3  \n",
       "269       3.0         2                0.7            NaN          3  \n",
       "\n",
       "[270 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_results, columns = analyze_paths(numpy_paths, run_ids, path_ids, pos_proba, target_proba, boundary_indices, poi_kde, cfe_kde)\n",
    "\n",
    "results = pd.DataFrame(data=numpy_results, columns=columns).merge(index_df, how='left', on='run_id').drop(columns=['dataset_name', 'max_iterations', 'model_type', 'noise_ratio', 'rescale_ratio', 'run_seed'])\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at the average metrics across the full batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>path_id</th>\n",
       "      <th>success</th>\n",
       "      <th>path_length</th>\n",
       "      <th>poi_density</th>\n",
       "      <th>cfe_density</th>\n",
       "      <th>sparsity</th>\n",
       "      <th>confidence_cutoff</th>\n",
       "      <th>max_step_size</th>\n",
       "      <th>num_paths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>15.058283</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>-361.105595</td>\n",
       "      <td>2.344444</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.251618</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>-346.905052</td>\n",
       "      <td>2.255556</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.715193</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>-4066.177519</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          run_id  path_id   success  path_length  poi_density  cfe_density  \\\n",
       "batch_id                                                                     \n",
       "0           14.5      1.0  0.944444    15.058283     0.081015  -361.105595   \n",
       "1           44.5      1.0  1.000000    16.251618     0.081015  -346.905052   \n",
       "2           74.5      1.0  1.000000    38.715193     0.081015 -4066.177519   \n",
       "\n",
       "          sparsity  confidence_cutoff  max_step_size  num_paths  \n",
       "batch_id                                                         \n",
       "0         2.344444                0.7            1.0        3.0  \n",
       "1         2.255556                0.7            2.0        3.0  \n",
       "2         2.000000                0.7            NaN        3.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('batch_id').mean().sort_values(['confidence_cutoff', 'num_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "619fa2c554ec4a197b8d20b7f9adefde21bd8fc532cb8fcddfe28bcef7d74d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
